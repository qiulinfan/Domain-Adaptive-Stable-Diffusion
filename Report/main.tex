\documentclass[10pt,twocolumn,letterpaper]{article} 
\usepackage[margin=0.8in, columnsep=0.25in]{geometry} % CVPR margins
\usepackage{times} % Standard CVPR font
\bibliographystyle{ieeetr}
\usepackage[backend=biber,style=numeric]{biblatex}
\addbibresource{reference.bib}
\usepackage{tikz}
\usepackage{float}
\usetikzlibrary{calc}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{positioning,fit,arrows.meta}
\usetikzlibrary{external}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath, amssymb}
\usepackage{capt-of}
\tikzset{
    module/.style={draw, thick, rounded corners, align=center},
    mytrape/.style 2 args={ % #1 = 填充色, #2 = 线条色
        trapezium, draw=#2!75, fill=#1!20, thick, text=black, align=center, 
    },
    io/.style={
        draw=green!40!black,
        fill=green!8!white,
        thick,
        rectangle,
        rounded corners=1pt,
        minimum size=0.55cm,
        font=\small,
        align=center
    },
    unetshape/.style={
        trapezium, trapezium left angle=80, trapezium right angle=100,
        trapezium stretches=true, fill=blue!10, draw=blue!60, thick,
        minimum width=2cm, minimum height=1cm, align=center
    },
    lorablock/.style={
        draw=orange!70!black, fill=orange!15,
        rounded corners=3pt, thick,
        minimum width=1.1cm, minimum height=0.6cm, align=center, font=\small
    }
}
\begin{document}

\title{Domain-Adaptive Stable Diffusion: Parameter-Efficient Adaptation of Latent Diffusion Models for Cross-Domain Image Synthesis}

\author{
Zhanhao Liu (zhanhaol@umich.edu), 
Huanchen Jia (jhuanch@umich.edu),\\
Qiulin Fan (rynnefan@umich.edu),
Kunlong Zhang (kunlong@umich.edu)
}

\date{December 9, 2025}
\maketitle

% ==========================================================
\section{Introduction}

Latent Diffusion Models (LDMs) like Stable Diffusion~\cite{rombach2022high} have revolutionized image synthesis but often struggle with specialized domains such as medical radiographs or satellite imagery. This failure stems from the drastic distribution shift between the pre-training data (e.g., LAION-5B) and the target domain. While full fine-tuning is computationally prohibitive, standard parameter-efficient methods like LoRA~\cite{hu2021lora} typically focus solely on reconstruction loss. We find this insufficient for structural domain shifts, as it fails to explicitly align the high-level semantic features of the pre-trained model with the new target distribution.

\noindent In this work, we propose \textbf{Domain-Adaptive Stable Diffusion (DASD)}, a framework to efficiently adapt LDMs to unseen domains using minimal data. Our approach makes three contributions: (1)  introduce a \textbf{hybrid adaptation strategy} injecting LoRA into both attention and convolutional layers to capture domain-specific structures; (2)  utilize \textbf{textual inversion} to ground domain-specific concepts (e.g., \texttt{<xray>}); and (3)  use a \textbf{Maximum Mean Discrepancy (MMD)} regularization loss to explicitly align source and target latent distributions, significantly reducing out-of-distribution hallucinations.

\section{Related Work}

\begin{itemize}
    \item \textbf{Low-Rank Adaptation (LoRA).} 
    LoRA~\cite{hu2021lora} is a parameter-efficient fine-tuning method that injects low-rank trainable updates into frozen pre-trained weights, enabling effective adaptation with minimal additional parameters while significantly reducing memory and computational overhead.

    \item \textbf{Stable Diffusion.} 
    Stable Diffusion~\cite{rombach2022high} is a latent diffusion model that performs denoising in a compressed latent space, enabling high-quality text-to-image generation with significantly reduced computational cost compared to pixel-space diffusion models. A detailed introduction and architectural illustration of Stable Diffusion are provided in Section~3.2.
\end{itemize}


% ==========================================================
\section{Method}
We propose a framework called \textbf{Domain-Adaptive Stable Diffusion (DASD)} to improve cross-domain performance through lightweight modules and feature alignment.

%--------------------------------------------
\subsection{DASD}
\vspace{1mm}  % small space to avoid awkward break
DASD provides a lightweight adaptation framework that enables Stable Diffusion
to generalize across domains with minimal data. As shown in 
Fig.~\ref{fig:dasd_overview}, we jointly adapt the UNet, text encoder, and latent 
features using LoRA modules, domain tokens, and an alignment loss. 
This hybrid strategy preserves the pretrained model's capacity while injecting 
domain-specific structure.
\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{diagram.png}
    \caption{Overview of the proposed Domain-Adaptive Stable Diffusion (DASD).
    LoRA adapters are inserted into the UNet, while domain tokens are introduced
    through the CLIP text encoder to enable domain-specific conditioning.}
    \label{fig:dasd_overview}
\end{figure}



%--------------------------------------------
\subsection{UNet}

\vspace{1mm}
The UNet in Stable Diffusion follows an encoder–decoder architecture with 
cross-attention and skip connections, as illustrated in 
Fig.~\ref{fig:UNet_overview} in the appendix. It learns rich semantic priors during large-scale 
pretraining but struggles under strong distribution shifts. 
Effective adaptation is therefore necessary to handle domains with 
distinct structural statistics.

%--------------------------------------------
\subsection{UNet with LoRA}
\vspace{1mm}
We adapt the UNet by inserting low-rank LoRA modules into its attention and 
mid-level convolution layers (Fig.~\ref{fig:UNet_with_LoRA_overview}). 
These adapters provide expressive domain-specific updates while keeping the 
backbone frozen. This yields a parameter-efficient yet stable way to specialize 
the model to new visual domains.
\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{diagram2.png}
    \caption{Stable Diffusion UNet architecture with LoRA.}
    \label{fig:UNet_with_LoRA_overview}
\end{figure}

%--------------------------------------------
\subsection*{Model Design}
DASD introduces three key components:
\begin{itemize}
  \item \textbf{UNet-Side Adaptation:} Low-rank LoRA adapters~\cite{hu2021lora} 
  are inserted into the UNet’s attention and mid-level convolution layers.
  \item \textbf{Text-Side Adaptation:} Domain tokens (e.g., \texttt{<mri>}, \texttt{<ukiyo-e>}) 
  learned via textual inversion improve semantic grounding.
  \item \textbf{Domain Alignment:} A lightweight alignment loss encourages 
  latent features of source/target domains to align.
\end{itemize}

\[
\mathcal{L} =
\mathbb{E}_{z_t, \epsilon, t}\!\left[\|\epsilon - \epsilon_\theta(z_t, t, \tau_\theta(y))\|_2^2\right]
+ \lambda_{\text{align}}\,\mathcal{L}_{\text{align}}.
\]

\subsection*{Inference Calibration}
We adjust CFG scale, sampling steps, and scheduler type to match the visual
statistics of each domain and ensure stable synthesis.

% ==========================================================
\section{Evaluation}
\subsection*{Datasets}
To adapt the base Stable Diffusion model to satellite and medical imaging domains, we fine-tuned the model using two small, domain-specific datasets:


\begin{itemize}
  \item \textbf{Satellite Imagery Dataset — arampacha/rsicd:} 
  \item \textbf{Medical X-ray Dataset — hf-vision/chest-xray-pneumonia}
  
\end{itemize}

\subsection*{Adaptation Setup}
We perform few-shot adaptation with $k\!\in\!\{20,50,200\}$ target-domain images. The VAE and most UNet/CLIP weights remain frozen, while only LoRA adapters, domain tokens, and alignment loss parameters are trained. Mini-batches include a small portion of source-domain images (target:source $\approx$ 3:1) for stability.


\subsection*{Metrics}
% Evaluation metrics include:
% \begin{itemize}
%   \item \textbf{Distributional quality:} FID and Fréchet-CLIP (CLIP-FID).
%   \item \textbf{Text–image consistency:} CLIP-Score between prompt and image.
%   \item \textbf{Domain conformity:} Accuracy/AUROC of an external domain classifier trained on real data.
% \end{itemize}
Each sample is paired with a natural language caption, but quantitatively measuring image–text alignment is challenging. In addition to human inspection, we use a CLIP-based metric that computes the cosine similarity between image and text embeddings, providing an objective measure of semantic alignment for direct comparison with the \textbf{baseline: Regular Stable Diffusion model without fine tuning}.\\
All experiments are performed at $512\times512$ resolution with fixed prompt sets and random seeds for fair comparison.

\subsection*{Result}
For each domain, we generated 20 images using both our DASD model and the baseline Stable Diffusion model, and computed the average CLIP similarity score between each generated image and its corresponding caption. The results show that our method consistently outperforms the baseline across both domains. Additional qualitative examples comparing Base Stable Diffusion and DASD 
are provided in Appendix Figure~\ref{fig:appendix_grid}.


\begin{figure}[h]
    \centering
    \includegraphics[width=\columnwidth]{CLIP.png}
    \caption{CLIP-Score comparison between Base SD and DASD across satellite and X-ray domains.}
    \label{fig:clip}
\end{figure}
\section{Conclusion}
We introduced DASD, a lightweight framework for adapting Stable Diffusion 
to specialized visual domains. By combining LoRA-based UNet updates, 
domain-specific textual tokens, and a simple alignment loss, DASD reduces 
distribution shift and improves semantic consistency. Few-shot experiments 
on satellite and X-ray datasets show clear gains over the base model. 
Future work will explore stronger alignment and broader multi-domain 
adaptation.

% ==========================================================
\clearpage   % force all floats to be output
\section{Citations}
\printbibliography

\section{Appendix}
\begin{figure}[H]
    \centering
    \includegraphics[width=\columnwidth]{diagram1.png}
    \caption{Stable Diffusion UNet architecture.}
    \label{fig:UNet_overview}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=\columnwidth]{q1.jpg}
    \caption{
    Qualitative comparison between Base Stable Diffusion (column 1 and 3) and our DASD model (column 2 and 4)
    on satellite and X-ray domains.
    }
    \label{fig:appendix_grid}
\end{figure}

\end{document}
